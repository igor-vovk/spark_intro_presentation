<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Spark Intro</title>

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/beige.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>Apache Spark</h1>
					<h2>Для новичков от новичков</h2>
					<p><img src="img/spark-logo.png" style="background: none; border: 0; box-shadow: none;"></p>
					<p>
						<small>
						Игорь Вовк<br>
						<a href="http://github.com/igorynia">http://github.com/igorynia</a> / <a href="http://facebook.com/igorynia">http://facebook.com/igorynia</a>
						</small>
					</p>
				</section>

				<section>
					<p>API есть для языков Scala, Java, Python</p>
					<p>Вся робота со Spark сводится к созданию новых RDD, трансформациях над существующими RDD, или вызов операций c RDD для вызова результата</p>
				</section>

				<section>
					<h3>Основная структура данных – RDD</h3>

					<p>Расшифровывается как Resilien Distributet Dataset</p>

					<p>
						<ul>
							<li>иммутабельная коллекция объектов</li>
							<li>каждый RDD разделен на несколько партишнов</li>
						</ul>
					</p>
				</section>

				<section>
					<h3>Создание RDD</h3>

					<ul>
						<li>можно загруить внешний датасет</li>
						<li>на основании коллекции объектов</li>
					</ul>

					<p>
						<pre><code data-trim contenteditable>
val lines = sc.textFile("README.md")

val lines2 = sc.parallelize(List("pandas", "i like pandas")
						</code></pre>
					</p>
				</section>

				<section>
					<p>
						Можно загружать данные из:

						<ul>
							<li>с локальной ФС, NFS, HDFS, Amazon S3 в текстовом формате, JSON, CSV, хадуповские SequenceFiles, сериализованные java-объекты</li>
							<li>БД, поддерживаются Cassandra, HBASE, Elasticsearch и любую JDBC-совместимую</li>
						</ul>
					</p>
				</section>

				<section>
					<h3>Операции с RDD</h3>

					<ul>
						<li>трансформации - операции над RDD возвращают новый RDD</li>
						<ul>
							<li>map</li>
							<li>filter</li>
						</ul>
						<li>действия - возвращают результат в основную програму</li>
						<ul>
							<li>count</li>
							<li>first</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>Трансформации</h3>

					<ul>
						<li>синтаксис похож на работу с коллекциями в Scala</li>
						<li>все операции lazy</li>
						<li>производятся только тогда, когда выполняется действие</li>
						<li>переиспользуемые данные можно заперсистить, вызвав метод .persist()</li>
					</ul>
				</section>

				<section>
					<h3>Действия</h3>

					<p>Операции, возвращающие данные в основную програму или записывающие данные во внешнее хранилище</p>
				</section>

				<section>
					<h2>Экосистема</h2>

					<img src="img/Spark_Ecosystem_Chart11.jpg">
				</section>

				<section>
					<h3>Spark Streaming</h3>

					<p>Если нужно анализировать не только собранные данные, но и потоки c новыми данными в реалтайме.</p>
					<p>Можно подключиться к HDFS, Flume, Kafka</p>
				</section>

				<section>
					<h3>Spark SQL</h3>

					<p>Можно выполнять SQL-запросы к данным Apache Hive, пишут что up to x100 раз быстрее чем Hive</p>
				</section>

				<section>
					<h3>GraphX</h3>

					<p>Работа с графами</p>
				</section>

				<section>
					<h2>Что почитать</h2>
					<ul>
						<li><i>Документация</i> <a href="https://spark.apache.org/documentation.html">https://spark.apache.org/documentation.html</a></li>
						<li><i>Learning Spark: Lightning-Fast Big Data Analysis</i> <a href="http://www.amazon.com/gp/product/B00SW0TY8O/">http://www.amazon.com/gp/product/B00SW0TY8O/</a></li>
						<li><i>Cloudera engeneering blog</i> <a href="http://blog.cloudera.com/blog/category/spark/">http://blog.cloudera.com/blog/category/spark/</a></li>
						<li><i>Databricks blog</i> <a href="https://databricks.com/blog">https://databricks.com/blog</a></li>
					</ul>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
